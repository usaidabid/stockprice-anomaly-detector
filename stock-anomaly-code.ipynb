{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319f619-8d89-473e-b223-bf1c6b229f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "import pandas as pd\n",
    "ds = pd.read_excel(\"yahoo_data.xlsx\")\n",
    "ds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37869f-fb70-4401-8237-6bb13dec1955",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting date as index\n",
    "ds.isnull().sum()\n",
    "ds['Date']= pd.to_datetime(ds['Date'])\n",
    "ds = ds.sort_values(by='Date')\n",
    "ds.set_index('Date', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0669a8-e3f0-4ab4-b072-1fd279406cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the SMA\n",
    "ds['SMA_200'] = ds['Close*'].rolling(window=200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe29257-4b96-40f1-95d9-014547e2a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating EMA\n",
    "ds['EMA_200'] = ds['Close*'].ewm(span=200,adjust = False).mean()\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff155b0a-7fab-4648-9eb4-c4ff3140d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating RSI\n",
    "delta = ds['Close*'].diff()\n",
    "gain = delta.where(delta>0 , 0)\n",
    "loss = -delta.where(delta<0, 0)\n",
    "avg_gain = gain.rolling (window = 14).mean()\n",
    "avg_loss = loss.rolling(window = 14).mean()\n",
    "rs = avg_gain/avg_loss\n",
    "rsi = 100 - (100 / (1+rs))\n",
    "ds['RSI'] = rsi          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a3dea-ae98-4c2b-b2da-31bdfe6dd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bea172-064f-41fc-982a-8b8e7309e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training isolation forest for anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "data = ds[['Close*', 'Volume']]\n",
    "model = IsolationForest (contamination = 0.01 , random_state = 42)\n",
    "model.fit(data)\n",
    "ds['Anamoly'] = model.predict(data)\n",
    "anamolies = ds[ds['Anamoly'] ==-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b0cad-a9e1-4488-8eec-715e2097dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anamolies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e387362-04e7-47b2-9a0d-c0943df83fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "anamolies.to_csv(\"anomalies_detected.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50a26f-d853-4d66-8c91-081beb0d070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b77e2-3c28-45a2-8b02-fe3a4db9f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the important libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251d56f-82d9-4879-ab80-d015a5bcaa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[['Close*']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914f8a5-f70e-43d2-b5d5-eb511adaa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ea6c7-e422-49dc-85bb-d04bf8b23d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence creation for lstm\n",
    "def create_sequences( data , time_steps):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(time_steps  , len(data)):\n",
    "        X.append(data[i-time_steps:i , 0])\n",
    "        Y.append(data[i , 0])\n",
    "    return np.array(X) , np.array(Y)\n",
    "time_steps = 60\n",
    "X, y = create_sequences(scaled_data, time_steps)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f21d2-e4f7-429a-9a8d-9c1acbae1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING AND TESTING DATA\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a151e1e0-c9cf-4f82-8910-8e99413bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the lstm model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input  \n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1], 1)))  \n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d39fd-e9fa-490f-84c5-0fd41958e724",
   "metadata": {},
   "outputs": [],
   "source": [
    " #training the lstm model\n",
    "history = model.fit(\n",
    "    X_train,  \n",
    "    y_train,  \n",
    "    epochs=10,  \n",
    "    batch_size=32,  \n",
    "    validation_data=(X_test, y_test),  \n",
    "    verbose=1  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b0aad-8ca5-477a-934f-8d253bc8b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation (Test Loss)\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401316b-755d-4be8-a7ed-5d43cc59a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the test data\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082fbd7-5b69-472d-a12e-414afd2006f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scaling of predictions to get the original values\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5870a79e-6110-4c41-9a4f-ab7d97770b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot actual vs predicted stock prices\n",
    "plt.plot(y_test, color='blue', label='Actual Price')\n",
    "plt.plot(predictions, color='red', label='Predicted Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238f348-dfd4-4bb6-aa4b-4b494c1a4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating model performance using mse and rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db00105-9d9a-48da-97e5-835e8014b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot main stock prices\n",
    "plt.plot(ds.index, ds['Close*'], label='Stock Price', color='blue')\n",
    "\n",
    "# Plot anomalies\n",
    "plt.scatter(ds[ds['Anamoly'] == -1].index, ds[ds['Anamoly'] == -1]['Close*'],\n",
    "            color='red', marker='x', label='Anomalies')\n",
    "\n",
    "# Graph \n",
    "plt.title('Stock Price with Detected Anomalies (Isolation Forest)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4eb6a4-e417-491f-bee9-510daf0a60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493ae16-e523-4502-9c20-a3e1fe4fa5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "st.title(\"ðŸ“ˆ Excel-Based Stock Anomaly Detector\")\n",
    "st.write(\"Upload an Excel file with 'Close*' column and Date as index\")\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader(\"Choose an Excel file\", type=[\"xlsx\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    try:\n",
    "        # Read Excel with index column (Date)\n",
    "        df = pd.read_excel(uploaded_file, index_col=0)\n",
    "        df.index = pd.to_datetime(df.index)  # ensure index is datetime\n",
    "        st.success(\"âœ… File uploaded successfully!\")\n",
    "\n",
    "        # Preview\n",
    "        st.subheader(\"ðŸ“Š Preview of Uploaded Data\")\n",
    "        st.write(df.head())\n",
    "\n",
    "        # Check for 'Close*' column\n",
    "        if 'Close*' in df.columns:\n",
    "            # Isolation Forest\n",
    "            model = IsolationForest(contamination=0.05)\n",
    "            df['Anomaly'] = model.fit_predict(df[['Close*']])\n",
    "            anomalies = df[df['Anomaly'] == -1]\n",
    "\n",
    "            # Plot\n",
    "            st.subheader(\"ðŸ“‰ Stock Close* with Anomalies\")\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(x=df.index, y=df['Close*'], name='Close* Price'))\n",
    "            fig.add_trace(go.Scatter(x=anomalies.index, y=anomalies['Close*'], mode='markers',\n",
    "                                     marker=dict(color='red', size=10), name='Anomalies'))\n",
    "            st.plotly_chart(fig)\n",
    "\n",
    "            # Show anomaly rows\n",
    "            st.subheader(\"ðŸ“Œ Detected Anomalies\")\n",
    "            st.write(anomalies[['Close*']])\n",
    "        else:\n",
    "            st.error(\"âŒ 'Close*' column missing in Excel file.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error reading Excel file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010bb1-9cb0-4b64-bf45-765bee94f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42508c-5a78-429e-97ef-90fa30785343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
